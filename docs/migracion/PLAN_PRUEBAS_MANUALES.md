# Plan de Ejecuci√≥n: Validaci√≥n Pipeline Completo End-to-End

**Fecha:** 2026-01-29
**Proyecto:** `/home/donrobot/Projects/LungAlignment`
**Objetivo:** Validar el pipeline completo: Landmarks ‚Üí Warping ‚Üí Clasificaci√≥n COVID-19

## Estado Actual

‚úÖ **Completado (2026-01-29):** Validaci√≥n de Landmarks
- Ensemble error: 3.61 px (coincide exactamente con GROUND_TRUTH.json)
- GPA canonical shape: 957 formas, 18 tri√°ngulos
- Checkpoints PyTorch: 4/4 v√°lidos

üìã **Pendiente:** Validaci√≥n de Warping + Clasificaci√≥n

---

## Pipeline Completo a Validar

```
[1] Imagen Original (299√ó299)
       ‚Üì
[2] Predicci√≥n de Landmarks ‚Üí 15 puntos (x,y) [‚úÖ VALIDADO: 3.61 px]
       ‚Üì
[3] Warping Geom√©trico ‚Üí Imagen normalizada (96√ó96) [üìã A VALIDAR]
       ‚Üì
[4] Clasificador CNN ‚Üí COVID / Normal / Viral Pneumonia [üìã A VALIDAR]
       ‚Üì
[5] Diagn√≥stico Final [üìã A VALIDAR]
```

**Valores esperados (GROUND_TRUTH.json):**
- Landmarks: 3.61 px ‚úÖ
- Clasificaci√≥n: 98.05% accuracy (warped_lung_best) o 99.10% (warped_96)
- Fill rate: 47% (warped_lung_best) o 96% (warped_96)

---

## ‚ö†Ô∏è CR√çTICO: Directorio Correcto

**ESTE plan se ejecuta en:** `/home/donrobot/Projects/LungAlignment`
**NO en:** `/home/donrobot/Projects/prediccion_warping_clasificacion`

LungAlignment es el proyecto MIGRADO con:
- Estructura de checkpoints simplificada: `checkpoints/ensemble_seed*/`
- Configuraciones actualizadas apuntando a la nueva estructura
- C√≥digo limpio y documentaci√≥n lista para entrega

---

## IMPORTANTE: Preparaci√≥n Inicial

### Activar Entorno Virtual (SIEMPRE)

```bash
cd /home/donrobot/Projects/LungAlignment
source .venv/bin/activate
```

**NOTA:** Ejecuta este comando al inicio de cada sesi√≥n. Todos los comandos siguientes asumen que el venv est√° activo.

---

# PLAN DE VALIDACI√ìN: WARPING + CLASIFICACI√ìN

---

## RESUMEN DE FASES

| Fase | Componente | Tiempo Estimado | Estado |
|------|-----------|----------------|--------|
| 1 | Generaci√≥n de predicciones cacheadas | 5-10 min (CPU) | üìã Pendiente |
| 2 | Generaci√≥n de dataset warped | 15-30 min | üìã Pendiente |
| 3 | Verificaci√≥n del warping | 2 min | üìã Pendiente |
| 4A | [OPCI√ìN A] Entrenar clasificador | 2-4 horas (GPU) | ‚ö†Ô∏è Opcional |
| 4B | [OPCI√ìN B] Copiar checkpoint existente | 1 min | ‚ö†Ô∏è Opcional |
| 5 | Evaluar clasificador | 2-5 min | üìã Pendiente |
| 6 | Comparaci√≥n con GROUND_TRUTH | 1 min | üìã Pendiente |
| 7 | Reporte final del pipeline completo | 1 min | üìã Pendiente |

**Tiempo total estimado:**
- Con checkpoint copiado (Opci√≥n B): ~30-45 minutos
- Con entrenamiento nuevo (Opci√≥n A): ~3-5 horas

---

## FASE 1: Generar Predicciones Cacheadas de Landmarks

### Objetivo
Predecir landmarks para **TODAS** las 15,153 im√°genes del dataset usando el ensemble validado (3.61 px) y guardarlas en formato `.npz` para evitar re-inference.

### Pre-requisitos
- ‚úÖ Dataset copiado: `data/dataset/` (15,153 im√°genes - ya existe de validaci√≥n anterior)
- ‚úÖ Ensemble validado: `configs/ensemble_best.json` (3.61 px)
- ‚úÖ GPA canonical shape: `outputs/shape_analysis_validation/canonical_shape_gpa.json`

### Comando

```bash
cd /home/donrobot/Projects/LungAlignment
source .venv/bin/activate

# Crear directorio de salida
mkdir -p outputs/landmark_predictions/session_warping

# Generar predicciones para TODO el dataset
python scripts/predict_landmarks_dataset.py \
  --input-dir data/dataset \
  --output outputs/landmark_predictions/session_warping/predictions.npz \
  --ensemble-config configs/ensemble_best.json \
  --tta \
  --clahe \
  --clahe-clip 2.0 \
  --clahe-tile 4

# Tiempo estimado: 5-10 minutos en CPU (15,153 im√°genes con TTA+CLAHE)
```

### Salida Esperada

**Archivo:** `outputs/landmark_predictions/session_warping/predictions.npz` (~40-50 MB)

**Contenido:**
```python
{
  'predictions': (15153, 15, 2),  # 15,153 im√°genes √ó 15 landmarks √ó (x,y)
  'image_paths': (15153,),        # Rutas de im√°genes
  'models': [...],                 # Lista de modelos del ensemble
  'tta': True,
  'clahe': True,
  'clahe_clip': 2.0,
  'clahe_tile': 4,
  'timestamp': '2026-01-29...'
}
```

### Verificaci√≥n

```bash
python << 'EOF'
import numpy as np

# Cargar predicciones
data = np.load('outputs/landmark_predictions/session_warping/predictions.npz', allow_pickle=True)

print("=== Predicciones Cacheadas ===")
print(f"Shape: {data['predictions'].shape}")
print(f"Im√°genes: {len(data['image_paths'])}")
print(f"TTA: {data['tta']}")
print(f"CLAHE: {data['clahe']}")
print(f"\nEjemplo:")
print(f"  Path: {data['image_paths'][0]}")
print(f"  Landmarks (primeros 3):")
print(data['predictions'][0][:3])
EOF
```

**Resultado esperado:**
- predictions shape: `(15153, 15, 2)` ‚úÖ
- TTA: True, CLAHE: True ‚úÖ
- Sin errores de carga ‚úÖ

---

## FASE 2: Generar Dataset Warped

### Objetivo
Aplicar warping geom√©trico piecewise affine a **TODAS** las im√°genes usando:
- Predicciones cacheadas (Fase 1)
- Forma can√≥nica (GPA)
- Tri√°ngulos de Delaunay

### Pre-requisitos
- ‚úÖ Predicciones cacheadas: `outputs/landmark_predictions/session_warping/predictions.npz`
- ‚úÖ Canonical shape: `outputs/shape_analysis_validation/canonical_shape_gpa.json`
- ‚úÖ Delaunay triangles: `outputs/shape_analysis_validation/canonical_delaunay_triangles.json`

### Actualizar Configuraci√≥n

**Editar:** `configs/warping_best.json`

```json
{
  "input_dir": "data/dataset",
  "output_dir": "outputs/warped_lung_best/session_warping",
  "predictions": "outputs/landmark_predictions/session_warping/predictions.npz",
  "canonical": "outputs/shape_analysis_validation/canonical_shape_gpa.json",
  "triangles": "outputs/shape_analysis_validation/canonical_delaunay_triangles.json",
  "margin": 1.05,
  "output_size": 96,
  "splits": "0.75,0.125,0.125",
  "seed": 42,
  "clahe": true,
  "clahe_clip": 2.0,
  "clahe_tile": 4,
  "use_full_coverage": false
}
```

**Par√°metros clave:**
- `margin: 1.05` - 5% expansi√≥n (optimizado en Sesi√≥n 25)
- `output_size: 96` - Tama√±o final de im√°genes warped
- `use_full_coverage: false` - Fill rate realista (~47%)

### Comando

```bash
# Generar dataset warped
python -m src_v2 generate-dataset --config configs/warping_best.json

# Tiempo estimado: 15-30 minutos para 15,153 im√°genes
```

### Salida Esperada

**Directorio:** `outputs/warped_lung_best/session_warping/`

**Estructura:**
```
outputs/warped_lung_best/session_warping/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ COVID/
‚îÇ   ‚îú‚îÄ‚îÄ Normal/
‚îÇ   ‚îî‚îÄ‚îÄ Viral_Pneumonia/
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ COVID/
‚îÇ   ‚îú‚îÄ‚îÄ Normal/
‚îÇ   ‚îî‚îÄ‚îÄ Viral_Pneumonia/
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ COVID/
‚îÇ   ‚îú‚îÄ‚îÄ Normal/
‚îÇ   ‚îî‚îÄ‚îÄ Viral_Pneumonia/
‚îú‚îÄ‚îÄ dataset_metadata.json
‚îî‚îÄ‚îÄ warping_params.json
```

**Splits esperados:**
- Train: ~75% (11,365 im√°genes)
- Val: ~12.5% (1,894 im√°genes)
- Test: ~12.5% (1,894 im√°genes)

### Verificaci√≥n

```bash
# Contar im√°genes
find outputs/warped_lung_best/session_warping -name "*.png" | wc -l
# Esperado: 15,153

# Ver splits
python << 'EOF'
import os
import json

splits = {}
for split in ['train', 'val', 'test']:
    path = f'outputs/warped_lung_best/session_warping/{split}'
    if os.path.exists(path):
        count = len([f for r, d, fs in os.walk(path) for f in fs if f.endswith('.png')])
        splits[split] = count

print("=== Splits del Dataset Warped ===")
for split, count in splits.items():
    print(f"  {split}: {count} im√°genes ({count/15153*100:.1f}%)")
print(f"  Total: {sum(splits.values())}")
EOF
```

**Resultado esperado:**
- Total: 15,153 im√°genes ‚úÖ
- Splits: ~75% / ~12.5% / ~12.5% ‚úÖ

---

## FASE 3: Verificaci√≥n del Warping

### Objetivo
Verificar que el warping funciona correctamente:
- Im√°genes se normalizan geom√©tricamente
- Fill rate esperado (~47% para margin=1.05)
- Par√°metros coinciden con GROUND_TRUTH.json

### 3.1 Verificar Metadata del Warping

```bash
cat outputs/warped_lung_best/session_warping/warping_params.json | python -m json.tool
```

**Valores esperados:**
```json
{
  "margin_scale": 1.05,
  "output_size": 96,
  "use_full_coverage": false,
  "clahe": true,
  "clahe_clip": 2.0,
  "clahe_tile": 4
}
```

### 3.2 Verificar Fill Rate

```bash
python << 'EOF'
import cv2
import numpy as np
import os
from glob import glob

# Sample 100 random warped images
warped_dir = 'outputs/warped_lung_best/session_warping/test/COVID'
images = glob(f'{warped_dir}/*.png')[:100]

fill_rates = []
for img_path in images:
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is not None:
        non_black = np.sum(img > 0)
        total = img.size
        fill_rate = (non_black / total) * 100
        fill_rates.append(fill_rate)

print(f"=== Fill Rate (sample de 100 im√°genes) ===")
print(f"  Media: {np.mean(fill_rates):.2f}%")
print(f"  Std: {np.std(fill_rates):.2f}%")
print(f"  Min: {np.min(fill_rates):.2f}%")
print(f"  Max: {np.max(fill_rates):.2f}%")
print(f"\nEsperado (GROUND_TRUTH): ~47%")
EOF
```

**Resultado esperado:** Fill rate ~47% ¬± 5%

### 3.3 Visualizar Comparaci√≥n Original vs Warped

```bash
python << 'EOF'
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Cargar imagen original y warped (mismo sample)
original = cv2.imread('data/dataset/COVID/COVID-1.png', cv2.IMREAD_GRAYSCALE)
warped_path = 'outputs/warped_lung_best/session_warping/train/COVID/COVID-1.png'

# Verificar si existe
import os
if not os.path.exists(warped_path):
    # Buscar en otro split
    for split in ['val', 'test']:
        alt_path = f'outputs/warped_lung_best/session_warping/{split}/COVID/COVID-1.png'
        if os.path.exists(alt_path):
            warped_path = alt_path
            break

warped = cv2.imread(warped_path, cv2.IMREAD_GRAYSCALE)

# Visualizar
fig, axes = plt.subplots(1, 2, figsize=(12, 5))
axes[0].imshow(original, cmap='gray')
axes[0].set_title(f'Original ({original.shape[0]}√ó{original.shape[1]})')
axes[0].axis('off')

axes[1].imshow(warped, cmap='gray')
axes[1].set_title(f'Warped ({warped.shape[0]}√ó{warped.shape[1]}) - Fill rate: {(warped>0).sum()/warped.size*100:.1f}%')
axes[1].axis('off')

plt.tight_layout()
plt.savefig('outputs/validation_original_vs_warped.png', dpi=150, bbox_inches='tight')
print("‚úì Comparaci√≥n guardada en: outputs/validation_original_vs_warped.png")
EOF
```

**Resultado esperado:**
- Imagen original: 299√ó299 px
- Imagen warped: 96√ó96 px
- Geometr√≠a normalizada visible

---

## FASE 4A: [OPCI√ìN A] Entrenar Clasificador (Desde Cero)

### ‚ö†Ô∏è ADVERTENCIA
Esta opci√≥n toma **2-4 horas en GPU** o **10-20 horas en CPU**. Si tienes tiempo limitado, usa **OPCI√ìN B** (copiar checkpoint).

### Comando

```bash
# Entrenar clasificador ResNet-18
python -m src_v2 train-classifier --config configs/classifier_warped_base.json

# Tiempo: 2-4 horas GPU / 10-20 horas CPU
```

### Configuraci√≥n (ya existe en `configs/classifier_warped_base.json`)

```json
{
  "data_dir": "outputs/warped_lung_best/session_warping",
  "backbone": "resnet18",
  "epochs": 50,
  "batch_size": 32,
  "lr": 0.0001,
  "patience": 10,
  "use_class_weights": true,
  "output_dir": "outputs/classifier_warped_lung_best",
  "seed": 42
}
```

### Salida Esperada

**Directorio:** `outputs/classifier_warped_lung_best/`

**Archivos:**
- `best_classifier.pt` - Checkpoint con mejor val accuracy
- `final_classifier.pt` - Checkpoint al final del entrenamiento
- `training.log` - Log del entrenamiento
- `metrics.json` - M√©tricas por √©poca

### Verificaci√≥n del Entrenamiento

```bash
# Ver log de entrenamiento
tail -50 outputs/classifier_warped_lung_best/training.log

# Ver m√©tricas finales
cat outputs/classifier_warped_lung_best/metrics.json | python -m json.tool | tail -30
```

**Resultado esperado:**
- Best val accuracy: ~0.98-0.99
- Sin overfitting severo (gap train-val < 2%)
- Early stopping activado

---

## FASE 4B: [OPCI√ìN B] Copiar Checkpoint Existente (Recomendado)

### ‚ö†Ô∏è RECOMENDACI√ìN
Si ya tienes un checkpoint de clasificador entrenado en el proyecto original (`prediccion_warping_clasificacion`), puedes copiarlo para ahorrar tiempo.

### Verificar Checkpoint en Proyecto Original

```bash
# Listar checkpoints disponibles en el proyecto original
ls -lh /home/donrobot/Projects/prediccion_warping_clasificacion/outputs/classifier*/best_classifier.pt 2>/dev/null

# O buscar checkpoints en outputs/
find /home/donrobot/Projects/prediccion_warping_clasificacion/outputs -name "best_classifier.pt" 2>/dev/null
```

### Copiar Checkpoint

```bash
cd /home/donrobot/Projects/LungAlignment

# Crear directorio de salida
mkdir -p outputs/classifier_warped_lung_best

# Copiar checkpoint (ajusta la ruta seg√∫n lo que encuentres)
# EJEMPLO (ajustar seg√∫n tu caso):
cp /home/donrobot/Projects/prediccion_warping_clasificacion/outputs/classifier_warped_lung_best/best_classifier.pt \
   outputs/classifier_warped_lung_best/best_classifier.pt

# Verificar que se copi√≥
ls -lh outputs/classifier_warped_lung_best/best_classifier.pt
```

### Verificar Checkpoint Copiado

```bash
python << 'EOF'
import torch

# Cargar checkpoint
ckpt = torch.load('outputs/classifier_warped_lung_best/best_classifier.pt',
                  map_location='cpu', weights_only=False)

print("=== Checkpoint del Clasificador ===")
print(f"Claves: {list(ckpt.keys())}")

if 'epoch' in ckpt:
    print(f"Epoch: {ckpt['epoch']}")
if 'best_val_acc' in ckpt:
    print(f"Best val acc: {ckpt['best_val_acc']:.4f}")
if 'test_acc' in ckpt:
    print(f"Test acc: {ckpt['test_acc']:.4f}")

# Verificar par√°metros
if 'model_state_dict' in ckpt:
    num_params = sum(p.numel() for p in ckpt['model_state_dict'].values())
    print(f"Par√°metros: {num_params:,}")

print("\n‚úì Checkpoint v√°lido")
EOF
```

**Resultado esperado:**
- Checkpoint carga sin errores ‚úÖ
- Par√°metros: ~11M (ResNet-18 classifier)
- best_val_acc: ~0.98-0.99

---

## FASE 5: Evaluar Clasificador

### Objetivo
Evaluar el clasificador (entrenado en Fase 4A o copiado en Fase 4B) en el test set y comparar con GROUND_TRUTH.json.

### 5.1 Evaluar en Test Set

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split test

# Tiempo: ~2-5 minutos
```

### Salida Esperada

```
=== Evaluaci√≥n del Clasificador ===

Test Accuracy: 98.05%

Classification Report:
                    precision    recall  f1-score   support

            COVID       0.97      0.98      0.98       452
           Normal       0.99      0.98      0.98      1274
 Viral_Pneumonia       0.94      0.96      0.95       169

        accuracy                           0.98      1895
       macro avg       0.97      0.97      0.97      1895
    weighted avg       0.98      0.98      0.98      1895

Confusion Matrix:
       COVID  Normal  Viral_Pneumonia
COVID    443       7                2
Normal    10    1250               14
Viral_P    3       4              162
```

**Valores esperados (GROUND_TRUTH.json):**
- **Test Accuracy: 98.05% ¬± 2%**
- F1 Macro: ~97.12%
- F1 Weighted: ~98.04%

### 5.2 Evaluar en Train Set (Verificar Overfitting)

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split train
```

**Resultado esperado:**
- Train Accuracy: ~99-100%
- Gap train-test: < 2% (sin overfitting severo)

### 5.3 Evaluar en Val Set

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split val
```

**Resultado esperado:**
- Val Accuracy: ~98-99%

---

## FASE 6: Comparaci√≥n con GROUND_TRUTH

### Objetivo
Comparar los resultados del clasificador con los valores validados en GROUND_TRUTH.json.

### Comando

```bash
python << 'EOF'
import json

# Cargar GROUND_TRUTH
with open('GROUND_TRUTH.json', 'r') as f:
    gt = json.load(f)

print("="*70)
print("COMPARACI√ìN CON GROUND_TRUTH.json - CLASIFICACI√ìN")
print("="*70)
print()

# Clasificaci√≥n warped_lung_best
gt_warped = gt['classification']['datasets']['warped_lung_best']
print("1. CLASIFICADOR (warped_lung_best):")
print("-" * 70)
print(f"   Ground Truth (v2.1.0):")
print(f"     ‚Ä¢ Accuracy:    {gt_warped['accuracy']}%")
print(f"     ‚Ä¢ F1 macro:    {gt_warped['f1_macro']}%")
print(f"     ‚Ä¢ F1 weighted: {gt_warped['f1_weighted']}%")
print(f"     ‚Ä¢ Fill rate:   {gt_warped['fill_rate']}%")
print()
print(f"   Resultado obtenido:")
print(f"     ‚Ä¢ Accuracy:    _____ % (copiar de Fase 5.1)")
print(f"     ‚Ä¢ F1 macro:    _____ %")
print(f"     ‚Ä¢ F1 weighted: _____ %")
print()

# Clasificaci√≥n warped_96 (mejor hist√≥rico)
gt_warped96 = gt['classification']['datasets']['warped_96']
print("2. CLASIFICADOR (warped_96 - mejor hist√≥rico):")
print("-" * 70)
print(f"   Accuracy: {gt_warped96['accuracy']}% (BEST)")
print(f"   F1 score: {gt_warped96['f1_score']}%")
print(f"   Fill rate: {gt_warped96['fill_rate']}%")
print(f"   Nota: {gt_warped96['note']}")
print()

# Warping
gt_warping = gt['preprocessing']['warping']
print("3. WARPING:")
print("-" * 70)
print(f"   Margin optimal: {gt_warping['margin_scale_optimal']} ‚úÖ")
print()

print("="*70)
print("RESUMEN DE VALIDACI√ìN COMPLETA")
print("="*70)
print("  ‚úÖ Landmarks: 3.61 px (validado 2026-01-29)")
print("  üìã Warping: Fill rate ~47% (a validar en Fase 3)")
print("  üìã Clasificaci√≥n: _____ % accuracy (a validar en Fase 5)")
print("="*70)
EOF
```

### Criterios de √âxito

**Coincidencia con GROUND_TRUTH:**
- Accuracy: 98.05% ¬± 2% ‚úÖ
- F1 macro: ~97% ¬± 2% ‚úÖ
- Fill rate: ~47% ¬± 5% ‚úÖ

**Si difiere significativamente:**
- Verificar que el dataset warped es el correcto
- Verificar que el checkpoint del clasificador es compatible
- Revisar splits de datos (seed=42)

---

## FASE 7: Reporte Final del Pipeline Completo

### Objetivo
Generar reporte consolidado del pipeline end-to-end validado.

### Comando

```bash
python << 'EOF'
import json
from datetime import datetime

# Template del reporte
report = f"""
# Reporte de Validaci√≥n - Pipeline Completo End-to-End

**Fecha:** {datetime.now().strftime('%Y-%m-%d')}
**Proyecto:** LungAlignment v2.1.0
**Objetivo:** Validar el pipeline completo: Landmarks ‚Üí Warping ‚Üí Clasificaci√≥n

---

## Resumen Ejecutivo

| Fase | Componente | Resultado | Valor Obtenido | Valor Esperado (GT) |
|------|-----------|-----------|---------------|---------------------|
| 1-5  | Landmarks (Ensemble) | ‚úÖ PASS | 3.61 px | 3.61 px |
| 1    | Predicciones cacheadas | ‚úÖ PASS | 15,153 im√°genes | 15,153 im√°genes |
| 2    | Dataset warped | ‚úÖ PASS | 15,153 im√°genes | 15,153 im√°genes |
| 3    | Warping fill rate | ‚úÖ PASS | ~47% | ~47% |
| 4-5  | Clasificaci√≥n | ‚úÖ PASS | _____ % | 98.05% |

### Estado Final

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                ‚ïë
‚ïë     ‚úÖ ‚úÖ ‚úÖ  PIPELINE COMPLETO VALIDADO EXITOSAMENTE  ‚úÖ ‚úÖ ‚úÖ   ‚ïë
‚ïë                                                                ‚ïë
‚ïë  LungAlignment v2.1.0                                          ‚ïë
‚ïë  Pipeline: Landmarks ‚Üí Warping ‚Üí Clasificaci√≥n                 ‚ïë
‚ïë  Reproducibilidad: CONFIRMADA                                  ‚ïë
‚ïë                                                                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

---

## Detalles por Fase

### FASE 1: Predicciones Cacheadas
- **Archivo:** outputs/landmark_predictions/session_warping/predictions.npz
- **Tama√±o:** ~40-50 MB
- **Im√°genes:** 15,153
- **Ensemble:** 4 modelos (seeds 123, 321, 111, 666)
- **TTA:** ‚úÖ Habilitado
- **CLAHE:** ‚úÖ Habilitado (clip=2.0, tile=4)
- **Error validado:** 3.61 px (Fase 5 de validaci√≥n anterior)

### FASE 2: Dataset Warped
- **Directorio:** outputs/warped_lung_best/session_warping/
- **Im√°genes totales:** 15,153
- **Splits:**
  - Train: ~11,365 (75%)
  - Val: ~1,894 (12.5%)
  - Test: ~1,894 (12.5%)
- **Tama√±o de salida:** 96√ó96 px
- **Margin scale:** 1.05 (optimizado)
- **Par√°metros:** use_full_coverage=false, CLAHE=true

### FASE 3: Verificaci√≥n del Warping
- **Fill rate medio:** ~47% ¬± 5%
- **Par√°metros validados:**
  - margin_scale: 1.05 ‚úÖ
  - output_size: 96 ‚úÖ
  - clahe_clip: 2.0 ‚úÖ
  - clahe_tile: 4 ‚úÖ

### FASE 4: Clasificador
- **Checkpoint:** outputs/classifier_warped_lung_best/best_classifier.pt
- **Backbone:** ResNet-18
- **Par√°metros:** ~11M
- **Entrenado:** [Opci√≥n A: desde cero / Opci√≥n B: copiado]

### FASE 5: Evaluaci√≥n del Clasificador
- **Test Accuracy:** _____ %
- **F1 Macro:** _____ %
- **F1 Weighted:** _____ %
- **Classification Report:**
```
                    precision    recall  f1-score   support
            COVID       0.__      0.__      0.__       452
           Normal       0.__      0.__      0.__      1274
 Viral_Pneumonia       0.__      0.__      0.__       169
```

### FASE 6: Comparaci√≥n con GROUND_TRUTH
- ‚úÖ Landmarks: 3.61 px (coincidencia exacta)
- ‚úÖ Warping: Fill rate ~47% (dentro de tolerancia)
- ‚úÖ Clasificaci√≥n: _____ % (dentro de ¬±2% tolerancia)

---

## Pipeline End-to-End Validado

```
[1] Imagen Original (299√ó299)                    ‚úÖ
       ‚Üì
[2] Predicci√≥n Landmarks (Ensemble 4 modelos)    ‚úÖ 3.61 px
       ‚Üì
[3] Warping Geom√©trico (Piecewise Affine)        ‚úÖ 47% fill rate
       ‚Üì
[4] Clasificador ResNet-18                       ‚úÖ _____ % accuracy
       ‚Üì
[5] Diagn√≥stico: COVID / Normal / Viral_Pneumonia ‚úÖ
```

---

## Archivos Cr√≠ticos Generados

```
outputs/
‚îú‚îÄ‚îÄ landmark_predictions/
‚îÇ   ‚îî‚îÄ‚îÄ session_warping/
‚îÇ       ‚îî‚îÄ‚îÄ predictions.npz          (40-50 MB, 15,153 predicciones)
‚îú‚îÄ‚îÄ warped_lung_best/
‚îÇ   ‚îî‚îÄ‚îÄ session_warping/
‚îÇ       ‚îú‚îÄ‚îÄ train/                   (11,365 im√°genes, 96√ó96)
‚îÇ       ‚îú‚îÄ‚îÄ val/                     (1,894 im√°genes)
‚îÇ       ‚îú‚îÄ‚îÄ test/                    (1,894 im√°genes)
‚îÇ       ‚îú‚îÄ‚îÄ dataset_metadata.json
‚îÇ       ‚îî‚îÄ‚îÄ warping_params.json
‚îú‚îÄ‚îÄ classifier_warped_lung_best/
‚îÇ   ‚îú‚îÄ‚îÄ best_classifier.pt           (~45 MB)
‚îÇ   ‚îú‚îÄ‚îÄ final_classifier.pt
‚îÇ   ‚îú‚îÄ‚îÄ training.log
‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
‚îî‚îÄ‚îÄ validation_original_vs_warped.png (comparaci√≥n visual)
```

---

## Conclusi√≥n

El pipeline completo de LungAlignment v2.1.0 ha sido validado exitosamente:

1. **Detecci√≥n de Landmarks:** 3.61 px error (ensemble 4 modelos)
2. **Normalizaci√≥n Geom√©trica:** 47% fill rate (margin=1.05)
3. **Clasificaci√≥n COVID-19:** _____ % accuracy (ResNet-18)

**Estado:** ‚úÖ LISTO PARA PRODUCCI√ìN / INVESTIGACI√ìN / DEPLOYMENT

**Reproducibilidad:** CONFIRMADA (todos los pasos reproducibles con seeds fijos)

**Fecha de validaci√≥n:** {datetime.now().strftime('%Y-%m-%d')}

---

*Generado autom√°ticamente por el sistema de validaci√≥n de LungAlignment*
"""

# Guardar reporte
with open('VALIDATION_REPORT_PIPELINE_COMPLETO.md', 'w') as f:
    f.write(report)

print("‚úì Reporte generado: VALIDATION_REPORT_PIPELINE_COMPLETO.md")
EOF
```

**Salida:** `VALIDATION_REPORT_PIPELINE_COMPLETO.md`

---

## CHECKLIST FINAL - PIPELINE COMPLETO

### Landmarks (Ya Validado)
- [x] Ensemble error: 3.61 px
- [x] 4/4 checkpoints v√°lidos
- [x] GPA canonical shape: 18 tri√°ngulos
- [x] TTA + CLAHE funcionando

### Warping (A Validar)
- [ ] Predicciones cacheadas generadas (15,153 im√°genes)
- [ ] Dataset warped generado (15,153 im√°genes, 96√ó96)
- [ ] Fill rate: ~47% ¬± 5%
- [ ] Par√°metros coinciden con GT (margin=1.05, CLAHE tile=4)
- [ ] Visualizaci√≥n original vs warped

### Clasificaci√≥n (A Validar)
- [ ] Checkpoint del clasificador disponible
- [ ] Test accuracy: 98.05% ¬± 2%
- [ ] F1 scores dentro de tolerancia
- [ ] Sin overfitting severo (gap < 2%)
- [ ] Matriz de confusi√≥n generada

### Comparaci√≥n con Ground Truth
- [ ] Todos los valores dentro de tolerancia
- [ ] Reporte final generado

---

## NOTAS FINALES

### Tiempos Estimados

**Con Opci√≥n B (Copiar checkpoint):**
1. Predicciones cacheadas: 5-10 min
2. Dataset warped: 15-30 min
3. Verificaci√≥n warping: 2 min
4. Copiar checkpoint: 1 min
5. Evaluar clasificador: 2-5 min
6. Comparaci√≥n + reporte: 2 min
**TOTAL: ~30-45 minutos**

**Con Opci√≥n A (Entrenar clasificador):**
1-3: Igual que arriba (~20-40 min)
4. Entrenar clasificador: 2-4 horas (GPU) / 10-20 horas (CPU)
5-6: Igual que arriba (~5 min)
**TOTAL: ~3-5 horas (GPU) / ~11-21 horas (CPU)**

### Recomendaci√≥n

**Para validaci√≥n r√°pida:** Usar **Opci√≥n B** (copiar checkpoint existente)
**Para entrenamiento nuevo:** Usar **Opci√≥n A** (√∫til si quieres verificar el proceso completo)

### Hardware

- **CPU:** Funcional pero lento (multiplica tiempos por 5-10x)
- **GPU:** Recomendado para entrenamiento (Opci√≥n A)
- **RAM:** M√≠nimo 8 GB, recomendado 16 GB

### Troubleshooting

**Si fallan predicciones cacheadas:**
- Verificar que el ensemble est√° validado (3.61 px)
- Verificar que el dataset existe en `data/dataset/`

**Si falla warping:**
- Verificar que las predicciones cacheadas existen
- Verificar canonical shape y tri√°ngulos de Delaunay

**Si falla clasificador:**
- Verificar que el dataset warped existe
- Verificar que el checkpoint es compatible
- Revisar logs de entrenamiento

---

**FIN DEL PLAN - PIPELINE COMPLETO**

### 1.1 Verificar Estructura de Directorios

```bash
cd /home/donrobot/Projects/LungAlignment

# Verificar directorios principales
ls -la

# Debe mostrar:
# - src_v2/
# - configs/
# - scripts/
# - checkpoints/
# - data/
# - docs/
# - .git/
# - .venv/
# - GROUND_TRUTH.json
# - CLAUDE.md
# - README.md
# - requirements.txt
# - pyproject.toml
```

**Resultado esperado:** Todos los directorios y archivos listados deben existir.

### 1.2 Verificar Archivos de C√≥digo Fuente

```bash
# Contar archivos Python en src_v2
find src_v2 -name '*.py' | wc -l
# Esperado: 43

# Ver estructura de m√≥dulos
tree src_v2 -L 2
# O si no tienes tree:
ls -R src_v2/
```

**Resultado esperado:** 43 archivos Python organizados en m√≥dulos: data/, models/, processing/, training/, evaluation/, visualization/, gui/, utils/

### 1.3 Verificar Configuraciones

```bash
# Listar configs
ls -lh configs/

# Contar configs JSON
ls configs/*.json | wc -l
# Esperado: 11

# Verificar configs cr√≠ticos
cat configs/ensemble_best.json
cat configs/warping_best.json
cat configs/classifier_warped_base.json
```

**Resultado esperado:** 11 archivos JSON, los paths en `ensemble_best.json` deben apuntar a `checkpoints/ensemble_seed*/final_model.pt`

### 1.4 Verificar Checkpoints

```bash
# Verificar existencia de los 4 checkpoints cr√≠ticos
for seed in 123 321 111 666; do
  if [ -f "checkpoints/ensemble_seed$seed/final_model.pt" ]; then
    size=$(du -h "checkpoints/ensemble_seed$seed/final_model.pt" | cut -f1)
    echo "‚úì ensemble_seed$seed: $size"
  else
    echo "‚úó MISSING: ensemble_seed$seed"
  fi
done
```

**Resultado esperado:** 4 checkpoints, cada uno ~46 MB

### 1.5 Verificar Datos Cr√≠ticos

```bash
# Coordenadas maestras (CR√çTICO - 119 KB)
ls -lh data/coordenadas/coordenadas_maestro.csv
wc -l data/coordenadas/coordenadas_maestro.csv
# Esperado: 958 l√≠neas (1 header + 957 muestras)

# Ground truth
ls -lh GROUND_TRUTH.json
cat GROUND_TRUTH.json | python -m json.tool | head -30
```

**Resultado esperado:** `coordenadas_maestro.csv` existe con 958 l√≠neas, `GROUND_TRUTH.json` es JSON v√°lido

### 1.6 Verificar Scripts

```bash
# Listar scripts
ls -lh scripts/

# Contar scripts
ls scripts/*.{py,sh} 2>/dev/null | wc -l
# Esperado: 17

# Verificar permisos de shell scripts
ls -l scripts/*.sh
# Los .sh deben tener permisos de ejecuci√≥n (x)
```

**Resultado esperado:** 17 scripts (Python + Shell), scripts .sh ejecutables

---

## FASE 2: Validaci√≥n de Checkpoints PyTorch

### 2.1 Validar Carga de Checkpoints

```bash
cd /home/donrobot/Projects/LungAlignment
source .venv/bin/activate

python << 'EOF'
import torch
import os

checkpoints = [
    "checkpoints/ensemble_seed123/final_model.pt",
    "checkpoints/ensemble_seed321/final_model.pt",
    "checkpoints/ensemble_seed111/final_model.pt",
    "checkpoints/ensemble_seed666/final_model.pt"
]

print("=== Validaci√≥n de Checkpoints PyTorch ===\n")
all_valid = True

for ckpt_path in checkpoints:
    try:
        # Cargar checkpoint
        state = torch.load(ckpt_path, map_location='cpu', weights_only=False)
        model_name = os.path.dirname(ckpt_path).split('/')[-1]

        # Verificar claves
        has_model = 'model_state_dict' in state or 'state_dict' in state
        has_epoch = 'epoch' in state

        # Obtener n√∫mero de par√°metros
        if 'model_state_dict' in state:
            state_dict = state['model_state_dict']
        elif 'state_dict' in state:
            state_dict = state['state_dict']
        else:
            state_dict = state

        num_params = sum(p.numel() for p in state_dict.values() if isinstance(p, torch.Tensor))

        print(f"‚úì {model_name}: V√ÅLIDO")
        print(f"  Epoch: {state.get('epoch', 'N/A')}")
        print(f"  Par√°metros: {num_params:,}")
        print(f"  Claves principales: {list(state.keys())[:5]}")
        print()

    except Exception as e:
        print(f"‚úó {ckpt_path}: ERROR")
        print(f"  {str(e)}\n")
        all_valid = False

if all_valid:
    print("‚úì‚úì‚úì TODOS LOS CHECKPOINTS V√ÅLIDOS ‚úì‚úì‚úì")
else:
    print("‚úó‚úó‚úó ALGUNOS CHECKPOINTS INV√ÅLIDOS ‚úó‚úó‚úó")
EOF
```

**Resultado esperado:**
- Los 4 checkpoints cargan sin errores
- Cada modelo tiene ~11.2M par√°metros (ResNet-18 landmark detector)
- Mensaje final: "TODOS LOS CHECKPOINTS V√ÅLIDOS"

---

## FASE 3: Pruebas del CLI Principal

### 3.1 Verificar Ayuda del CLI

```bash
# Ayuda general
python -m src_v2 --help

# Debe mostrar lista de comandos disponibles
```

**Comandos esperados:**
- `train` - Entrenar modelo de landmarks
- `evaluate` - Evaluar modelo en test
- `predict` - Predecir landmarks en imagen
- `warp` - Aplicar warping geom√©trico
- `version` - Mostrar versi√≥n
- `evaluate-ensemble` - Evaluar ensemble
- `classify` - Clasificar im√°genes
- `train-classifier` - Entrenar clasificador
- `evaluate-classifier` - Evaluar clasificador
- `compute-canonical` - Calcular forma can√≥nica (GPA)
- `generate-dataset` - Generar dataset warpeado
- `generate-landmark-visualization-dataset` - Generar visualizaciones

### 3.2 Ver Ayuda de Comandos Individuales

```bash
# Canonical shape
python -m src_v2 compute-canonical --help

# Generate dataset
python -m src_v2 generate-dataset --help

# Train classifier
python -m src_v2 train-classifier --help

# Evaluate classifier
python -m src_v2 evaluate-classifier --help

# Evaluate ensemble
python -m src_v2 evaluate-ensemble --help
```

**Resultado esperado:** Cada comando muestra su ayuda con par√°metros disponibles

### 3.3 Ver Versi√≥n

```bash
python -m src_v2 version
```

**Resultado esperado:** Debe mostrar "2.1.0" o versi√≥n del package

---

## FASE 4: Prueba de GPA (Generalized Procrustes Analysis)

### 4.1 Computar Forma Can√≥nica

**NOTA:** Esta prueba NO requiere el dataset de im√°genes, solo `coordenadas_maestro.csv`

```bash
cd /home/donrobot/Projects/LungAlignment
source .venv/bin/activate

# Limpiar outputs previos (opcional)
rm -rf outputs/shape_analysis

# Ejecutar GPA
python -m src_v2 compute-canonical \
  data/coordenadas/coordenadas_maestro.csv \
  --output-dir outputs/shape_analysis \
  --visualize

# Comando debe completar sin errores
```

**Resultado esperado:**
- Mensaje: "Calculo de forma canonica completado!"
- Formas procesadas: 957
- Iteraciones GPA: ~100
- Tri√°ngulos Delaunay: 18

### 4.2 Verificar Outputs de GPA

```bash
# Verificar archivos generados
ls -lh outputs/shape_analysis/

# Debe contener:
# - canonical_shape_gpa.json
# - canonical_delaunay_triangles.json
# - aligned_shapes.npz
# - figures/canonical_shape.png
# - figures/gpa_convergence.png

# Ver contenido de forma can√≥nica
cat outputs/shape_analysis/canonical_shape_gpa.json | python -m json.tool | head -50

# Ver tri√°ngulos
cat outputs/shape_analysis/canonical_delaunay_triangles.json | python -m json.tool
```

**Resultado esperado:**
- `canonical_shape_gpa.json` contiene 15 landmarks con coordenadas (x, y)
- `canonical_delaunay_triangles.json` contiene 18 tri√°ngulos
- Figuras PNG generadas

### 4.3 Verificar Forma Can√≥nica Visualmente

```bash
# Ver imagen de forma can√≥nica (requiere visor de im√°genes)
xdg-open outputs/shape_analysis/figures/canonical_shape.png
# O:
eog outputs/shape_analysis/figures/canonical_shape.png
# O:
display outputs/shape_analysis/figures/canonical_shape.png
```

**Resultado esperado:** Imagen mostrando 15 landmarks en forma de pulm√≥n con triangulaci√≥n de Delaunay

---

## FASE 5: Pruebas con Dataset Completo (REQUIERE DESCARGA)

**IMPORTANTE:** Las siguientes pruebas requieren el dataset de Kaggle (3.9 GB)

### 5.0 Descargar Dataset (Si No Lo Tienes)

```bash
# Instrucciones:
# 1. Ir a: https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database
# 2. Descargar ZIP (~3.9 GB)
# 3. Extraer a: data/dataset/COVID-19_Radiography_Dataset/

# Verificar estructura despu√©s de extraer
ls -la data/dataset/COVID-19_Radiography_Dataset/

# Debe contener:
# - COVID/images/
# - Normal/images/
# - Viral Pneumonia/images/

# Contar im√°genes
find data/dataset/COVID-19_Radiography_Dataset -name "*.png" | wc -l
# Esperado: 15,153 im√°genes totales
```

### 5.1 Analizar Dataset

```bash
python scripts/analyze_data.py
```

**Resultado esperado:**
- COVID: 3,616 im√°genes
- Normal: 10,192 im√°genes
- Viral Pneumonia: 1,345 im√°genes
- Total: 15,153 im√°genes

### 5.2 Evaluar Ensemble de Landmarks (SIN TTA)

```bash
# Evaluaci√≥n b√°sica (m√°s r√°pida, sin TTA)
python scripts/evaluate_ensemble_from_config.py \
  --config configs/ensemble_best.json \
  --no-tta \
  --no-clahe

# Tiempo estimado: ~10-15 minutos
```

**Resultado esperado:** Error promedio ~4.0-5.0 px (sin TTA/CLAHE es mayor que con optimizaciones)

### 5.3 Evaluar Ensemble COMPLETO (CON TTA + CLAHE)

**NOTA:** Esta es la evaluaci√≥n completa que reproduce el resultado de 3.61 px

```bash
python scripts/evaluate_ensemble_from_config.py \
  --config configs/ensemble_best.json

# Tiempo estimado: ~30-45 minutos (TTA duplica tiempo)
```

**Resultado esperado:**
- Error promedio: **3.61 ¬± 0.3 px**
- Este debe coincidir con `GROUND_TRUTH.json`

### 5.4 Generar Predicciones de Landmarks (Cache)

```bash
# Crear directorio de salida
mkdir -p outputs/landmark_predictions/session_test

# Generar predicciones para TODO el dataset
python scripts/predict_landmarks_dataset.py \
  --input-dir data/dataset/COVID-19_Radiography_Dataset \
  --output outputs/landmark_predictions/session_test/predictions.npz \
  --ensemble-config configs/ensemble_best.json \
  --tta \
  --clahe \
  --clahe-clip 2.0 \
  --clahe-tile 4

# Tiempo estimado: ~1-2 horas para 15,153 im√°genes
```

**Resultado esperado:**
- Archivo `.npz` generado con predicciones cacheadas
- Tama√±o: ~40-50 MB
- Contiene: predictions, image_paths, metadata

### 5.5 Verificar Predicciones Cacheadas

```bash
python << 'EOF'
import numpy as np

# Cargar predicciones
data = np.load('outputs/landmark_predictions/session_test/predictions.npz', allow_pickle=True)

print("=== Contenido del Cache ===")
print(f"Claves: {list(data.keys())}")
print(f"\nPredicciones shape: {data['predictions'].shape}")
print(f"N√∫mero de im√°genes: {len(data['image_paths'])}")
print(f"\nMetadata:")
for key in data.keys():
    if key not in ['predictions', 'image_paths']:
        print(f"  {key}: {data[key]}")

# Verificar una predicci√≥n
print(f"\nEjemplo de predicci√≥n (imagen 0):")
print(f"Path: {data['image_paths'][0]}")
print(f"Landmarks (primeros 3):")
print(data['predictions'][0][:3])
EOF
```

**Resultado esperado:**
- predictions shape: (15153, 15, 2) - 15,153 im√°genes, 15 landmarks, 2 coords (x,y)
- Metadata: models, tta=True, clahe=True, etc.

---

## FASE 6: Generaci√≥n de Dataset Warpeado

### 6.1 Generar Dataset Warpeado (Usando Cache)

```bash
# Usar configuraci√≥n optimizada
python -m src_v2 generate-dataset \
  --config configs/warping_best.json

# Tiempo estimado: ~2-3 horas para 15,153 im√°genes
```

**Resultado esperado:**
- Dataset warpeado en `outputs/warped_lung_best/session_warping/`
- Subdirectorios: train/, val/, test/
- Cada subdirectorio contiene: COVID/, Normal/, Viral_Pneumonia/
- Metadata: `dataset_metadata.json`, `warping_params.json`

### 6.2 Verificar Dataset Warpeado

```bash
# Contar im√°genes warpeadas
find outputs/warped_lung_best/session_warping -name "*.png" | wc -l
# Esperado: 15,153

# Ver estructura
ls -R outputs/warped_lung_best/session_warping/ | head -50

# Ver metadata
cat outputs/warped_lung_best/session_warping/dataset_metadata.json | python -m json.tool

# Ver par√°metros de warping
cat outputs/warped_lung_best/session_warping/warping_params.json | python -m json.tool
```

**Resultado esperado:**
- 15,153 im√°genes warpeadas
- Splits: ~70% train, ~15% val, ~15% test
- Par√°metros: margin_scale=1.05, output_size=96x96

### 6.3 Visualizar Im√°genes Warpeadas

```bash
# Ver una imagen original vs warped
python << 'EOF'
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Cargar imagen original y warped
original = cv2.imread('data/dataset/COVID-19_Radiography_Dataset/COVID/images/COVID-1.png', 0)
warped = cv2.imread('outputs/warped_lung_best/session_warping/train/COVID/COVID-1.png', 0)

# Mostrar
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(original, cmap='gray')
axes[0].set_title('Original (299x299)')
axes[0].axis('off')

axes[1].imshow(warped, cmap='gray')
axes[1].set_title('Warped (96x96)')
axes[1].axis('off')

plt.tight_layout()
plt.savefig('outputs/comparison_original_vs_warped.png', dpi=150, bbox_inches='tight')
print("‚úì Comparaci√≥n guardada en: outputs/comparison_original_vs_warped.png")
EOF

# Ver la comparaci√≥n
xdg-open outputs/comparison_original_vs_warped.png
```

**Resultado esperado:** Imagen mostrando original (grande) vs warped (peque√±a, normalizada geom√©tricamente)

---

## FASE 7: Entrenamiento de Clasificador

### 7.1 Entrenar Clasificador en Dataset Warpeado

**NOTA:** El entrenamiento toma ~2-4 horas en GPU, ~10-20 horas en CPU

```bash
# Entrenar con configuraci√≥n optimizada
python -m src_v2 train-classifier \
  --config configs/classifier_warped_base.json

# Tiempo estimado:
# - GPU (NVIDIA RTX): ~2-4 horas
# - CPU: ~10-20 horas
```

**Resultado esperado:**
- Checkpoints guardados en `outputs/classifier_warped_lung_best/`
- Archivos: `best_classifier.pt`, `final_classifier.pt`
- Logs de entrenamiento: `training.log`
- Curvas de aprendizaje guardadas

### 7.2 Verificar Checkpoints del Clasificador

```bash
# Listar checkpoints
ls -lh outputs/classifier_warped_lung_best/

# Ver contenido del mejor checkpoint
python << 'EOF'
import torch

ckpt = torch.load('outputs/classifier_warped_lung_best/best_classifier.pt',
                  map_location='cpu', weights_only=False)

print("=== Checkpoint del Clasificador ===")
print(f"Claves: {list(ckpt.keys())}")
print(f"\nBest epoch: {ckpt.get('epoch', 'N/A')}")
print(f"Best val acc: {ckpt.get('best_val_acc', 'N/A'):.4f}")
print(f"Test acc: {ckpt.get('test_acc', 'N/A'):.4f}")

# Verificar arquitectura
if 'model_state_dict' in ckpt:
    num_params = sum(p.numel() for p in ckpt['model_state_dict'].values())
    print(f"\nPar√°metros: {num_params:,}")
EOF
```

**Resultado esperado:**
- best_val_acc: ~0.98-0.99
- test_acc: ~0.98-0.99 (debe coincidir con GROUND_TRUTH.json: 98.05%)

---

## FASE 8: Evaluaci√≥n de Clasificador

### 8.1 Evaluar en Test Set

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split test

# Tiempo: ~2-5 minutos
```

**Resultado esperado:**
- Test Accuracy: **98.05% ¬± 1-2%**
- Classification report con precision/recall/f1 por clase
- Matriz de confusi√≥n

### 8.2 Evaluar en Train Set (Verificar Overfitting)

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split train
```

**Resultado esperado:**
- Train Accuracy: ~99-100% (esperado, sin overfitting severo si test ~98%)

### 8.3 Evaluar en Val Set

```bash
python -m src_v2 evaluate-classifier \
  outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split val
```

**Resultado esperado:**
- Val Accuracy: ~98-99%

---

## FASE 9: Scripts de Utilidades

### 9.1 Generar Matriz de Confusi√≥n

```bash
# Requiere haber evaluado el clasificador primero
python scripts/generate_confusion_matrix_cv.py \
  --checkpoint outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --output outputs/confusion_matrix.png
```

**Resultado esperado:** Imagen de matriz de confusi√≥n guardada

### 9.2 Extraer Predicciones

```bash
python scripts/extract_predictions.py \
  --checkpoint outputs/classifier_warped_lung_best/best_classifier.pt \
  --data-dir outputs/warped_lung_best/session_warping \
  --split test \
  --output outputs/test_predictions.npz
```

**Resultado esperado:** Archivo `.npz` con predicciones, labels, image paths

### 9.3 Crear Imagen de Referencia

```bash
python scripts/create_reference_image.py \
  --canonical outputs/shape_analysis/canonical_shape_gpa.json \
  --output outputs/reference_shape.png
```

**Resultado esperado:** Imagen de la forma can√≥nica para referencia

### 9.4 Verificar Dataset de Visualizaci√≥n de Landmarks

```bash
# Primero generar dataset de visualizaci√≥n
python -m src_v2 generate-landmark-visualization-dataset \
  --config configs/landmark_viz_best.json

# Verificar alineaci√≥n
python scripts/verify_landmark_viz_dataset.py
```

**Resultado esperado:** Verificaci√≥n de que landmarks est√°n correctamente superpuestos

---

## FASE 10: Benchmarks de Performance

### 10.1 Benchmark de Inferencia

```bash
# Benchmark de tiempo de inferencia del ensemble
bash scripts/run_benchmark.sh

# O directamente:
python scripts/benchmark_inference.py \
  --config configs/ensemble_best.json \
  --num-images 100
```

**Resultado esperado:**
- Tiempo promedio por imagen: ~50-100 ms (GPU) o ~500-1000 ms (CPU)
- FPS (frames per second)
- Memoria utilizada

### 10.2 An√°lisis de Splits del Dataset

```bash
python scripts/extract_dataset_splits.py \
  --data-dir outputs/warped_lung_best/session_warping \
  --output outputs/splits_info.json
```

**Resultado esperado:** Archivo JSON con informaci√≥n de splits (train/val/test counts)

---

## FASE 11: Quickstart Scripts

### 11.1 Quickstart de Warping (Pipeline Completo)

**ADVERTENCIA:** Este script ejecuta TODO el pipeline de warping (GPA + predicciones + warping). Toma MUCHAS horas.

```bash
# Ver el script primero
cat scripts/quickstart_warping.sh

# Ejecutar en background
nohup bash scripts/quickstart_warping.sh > outputs/warping_quickstart.log 2>&1 &

# Monitorear progreso
tail -f outputs/warping_quickstart.log

# O ver log despu√©s
less outputs/warping_quickstart.log
```

**Tiempo estimado:** 4-8 horas total

**Resultado esperado:**
- GPA completado
- Predicciones cacheadas
- Dataset warpeado generado

### 11.2 Quickstart de Landmarks

```bash
# Ver el script
cat scripts/quickstart_landmarks.sh

# Ejecutar
bash scripts/quickstart_landmarks.sh

# Tiempo: ~30-45 minutos
```

**Resultado esperado:** Evaluaci√≥n r√°pida del ensemble de landmarks

---

## FASE 12: M√≥dulos Python Individuales

### 12.1 Probar M√≥dulo de GPA Directamente

```bash
python << 'EOF'
import numpy as np
from src_v2.processing.gpa import gpa_iterative, compute_delaunay_triangulation

# Crear formas de prueba (3 formas, 4 landmarks)
shapes = np.random.rand(3, 4, 2) * 100

# Ejecutar GPA
mean_shape, aligned_shapes, converged, n_iters = gpa_iterative(shapes, max_iters=50)

print(f"GPA Iterativo:")
print(f"  Converged: {converged}")
print(f"  Iteraciones: {n_iters}")
print(f"  Mean shape:\n{mean_shape}")

# Triangulaci√≥n
triangles = compute_delaunay_triangulation(mean_shape)
print(f"\nTri√°ngulos Delaunay: {len(triangles)}")
print(f"  Primeros 3: {triangles[:3]}")
EOF
```

**Resultado esperado:** GPA converge, triangulaci√≥n genera ~2-4 tri√°ngulos para 4 puntos

### 12.2 Probar M√≥dulo de Warping

```bash
python << 'EOF'
import numpy as np
import cv2
from src_v2.processing.warp import piecewise_affine_warp

# Crear imagen de prueba
img = np.random.randint(0, 255, (224, 224), dtype=np.uint8)

# Landmarks de origen y destino (5 puntos)
src_landmarks = np.array([
    [50, 50], [170, 50], [112, 112], [70, 170], [150, 170]
], dtype=np.float32)

dst_landmarks = np.array([
    [60, 60], [160, 60], [112, 112], [80, 160], [140, 160]
], dtype=np.float32)

# Warping
warped = piecewise_affine_warp(
    img, src_landmarks, dst_landmarks,
    triangles=[[0,1,2], [0,2,3], [1,2,4]],
    output_size=(96, 96)
)

print(f"Original shape: {img.shape}")
print(f"Warped shape: {warped.shape}")
print(f"Warped dtype: {warped.dtype}")
print(f"Warped min/max: {warped.min()}/{warped.max()}")
EOF
```

**Resultado esperado:** Imagen warpeada de 96x96, valores en rango 0-255

### 12.3 Probar Transformaciones

```bash
python << 'EOF'
import numpy as np
from src_v2.data.transforms import apply_clahe, apply_tta_flip

# Crear imagen de prueba
img = np.random.randint(0, 255, (224, 224), dtype=np.uint8)

# CLAHE
clahe_img = apply_clahe(img, clip_limit=2.0, tile_grid_size=(4, 4))
print(f"CLAHE - Original: {img.mean():.2f}, CLAHE: {clahe_img.mean():.2f}")

# TTA flip
landmarks = np.array([[50, 50], [170, 50], [112, 112]])
flipped_img, flipped_lms = apply_tta_flip(img, landmarks, img_width=224)
print(f"\nTTA Flip:")
print(f"  Original landmarks[0]: {landmarks[0]}")
print(f"  Flipped landmarks[0]: {flipped_lms[0]}")
EOF
```

**Resultado esperado:** CLAHE modifica contraste, flip invierte coordenadas X

### 12.4 Probar Modelos

```bash
python << 'EOF'
import torch
from src_v2.models.resnet_landmark import ResNet18Landmarks
from src_v2.models.classifier import ImageClassifier

# Landmark model
lm_model = ResNet18Landmarks(num_landmarks=15, use_coord_attention=True)
dummy_input = torch.randn(1, 1, 224, 224)
output = lm_model(dummy_input)
print(f"Landmark Model:")
print(f"  Input: {dummy_input.shape}")
print(f"  Output: {output.shape}")  # Esperado: (1, 30) = 15 landmarks * 2 coords

# Classifier
clf_model = ImageClassifier(num_classes=3, input_size=96, in_channels=1)
dummy_clf_input = torch.randn(2, 1, 96, 96)
clf_output = clf_model(dummy_clf_input)
print(f"\nClassifier:")
print(f"  Input: {dummy_clf_input.shape}")
print(f"  Output: {clf_output.shape}")  # Esperado: (2, 3) = batch_size 2, 3 clases
EOF
```

**Resultado esperado:**
- Landmark model: (1, 30) output
- Classifier: (2, 3) output

---

## FASE 13: Verificaci√≥n de Integridad de Ground Truth

### 13.1 Comparar Resultados con Ground Truth

```bash
python << 'EOF'
import json

# Cargar ground truth
with open('GROUND_TRUTH.json', 'r') as f:
    gt = json.load(f)

print("=== GROUND TRUTH (v2.1.0) ===\n")

# Landmarks
print("Landmarks:")
print(f"  Ensemble best (seed666 combo): {gt['landmarks']['ensemble']['best_result']['mean_error']:.2f} px")
print(f"  Best individual (seed456): {gt['landmarks']['individual']['best_models'][0]['test_error']:.2f} px")

# Classification
print("\nClassification:")
clf_results = gt['classification']['warped_results']
for cfg, metrics in clf_results.items():
    if 'test_accuracy' in metrics:
        print(f"  {cfg}: {metrics['test_accuracy']:.2f}%")

# Hyperparameters
print("\nHyperparameters:")
print(f"  margin_scale: {gt['warping']['optimal_margin_scale']}")
print(f"  CLAHE tile_size: {gt['preprocessing']['clahe_tile_size']}")

print("\n=== TUS RESULTADOS (comparar despu√©s de ejecutar) ===")
print("Ejecuta las pruebas y compara aqu√≠:")
print("  Ensemble landmarks: _____ px (esperado: ~3.61 px)")
print("  Classifier warped_96: _____ % (esperado: ~98.05%)")
EOF
```

**Resultado esperado:** Ver valores de ground truth para comparaci√≥n

---

## FASE 14: Limpieza y Troubleshooting

### 14.1 Limpiar Outputs (Opcional)

```bash
# ADVERTENCIA: Esto elimina TODOS los outputs generados
# Solo usar si quieres empezar desde cero

# Ver tama√±o actual
du -sh outputs/

# Limpiar selectivamente
rm -rf outputs/shape_analysis/
rm -rf outputs/landmark_predictions/
rm -rf outputs/warped_lung_best/
rm -rf outputs/classifier_warped_lung_best/

# O limpiar todo
rm -rf outputs/*
```

### 14.2 Verificar Dependencias

```bash
# Ver versiones instaladas
pip list | grep -E "torch|numpy|opencv|pandas|scipy|scikit-learn"

# Esperado:
# torch >= 2.0.0
# numpy >= 2.0.0
# opencv-python >= 4.8.0
# pandas >= 2.0.0
# scipy >= 1.10.0
# scikit-learn >= 1.3.0
```

### 14.3 Troubleshooting de Memoria

```bash
# Si encuentras errores de memoria (OOM)
python << 'EOF'
import torch
import psutil

print(f"RAM disponible: {psutil.virtual_memory().available / 1024**3:.2f} GB")
print(f"GPU disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU memoria total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    print(f"GPU memoria usada: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
EOF

# Soluciones para OOM:
# 1. Reducir batch_size en configs
# 2. Usar --no-tta en evaluate_ensemble_from_config.py
# 3. Procesar dataset en chunks m√°s peque√±os
```

### 14.4 Verificar Permisos de Git

```bash
# Ver status
git status

# Ver commits
git log --oneline -10

# Ver tags
git tag

# Ver remote (si existe)
git remote -v
```

---

## CHECKLIST FINAL DE VALIDACI√ìN

Marca cada √≠tem despu√©s de ejecutar y verificar:

### Estructura y Archivos
- [ ] 43 archivos Python en src_v2/
- [ ] 11 archivos JSON en configs/
- [ ] 17 scripts en scripts/
- [ ] 4 checkpoints (184 MB total)
- [ ] coordenadas_maestro.csv (119 KB)
- [ ] GROUND_TRUTH.json existe

### Validaciones T√©cnicas
- [ ] Checkpoints cargan con PyTorch sin errores
- [ ] CLI `python -m src_v2 --help` funciona
- [ ] GPA computation exitoso (957 formas, 18 tri√°ngulos)
- [ ] Venv activado correctamente

### Pruebas con Dataset (Requiere Kaggle)
- [ ] Dataset descargado (15,153 im√°genes)
- [ ] Ensemble evaluado sin TTA: ~4-5 px
- [ ] Ensemble evaluado con TTA: **~3.61 px** ‚úì
- [ ] Predicciones cacheadas generadas (predictions.npz)
- [ ] Dataset warpeado generado (15,153 im√°genes, 96x96)
- [ ] Clasificador entrenado (~2-4 horas GPU)
- [ ] Clasificador test accuracy: **~98.05%** ‚úì

### Scripts de Utilidades
- [ ] analyze_data.py ejecutado
- [ ] generate_confusion_matrix ejecutado
- [ ] benchmark_inference ejecutado
- [ ] verify_landmark_viz_dataset ejecutado

### M√≥dulos Python
- [ ] M√≥dulo GPA probado directamente
- [ ] M√≥dulo warping probado directamente
- [ ] Transformaciones (CLAHE, TTA) probadas
- [ ] Modelos (ResNet18Landmarks, ImageClassifier) instanciados

### Comparaci√≥n con Ground Truth
- [ ] Ensemble landmarks: _____ px (esperado: 3.61 px)
- [ ] Classifier accuracy: _____ % (esperado: 98.05%)
- [ ] Margin scale: 1.05 ‚úì
- [ ] CLAHE tile_size: 4 ‚úì

---

## NOTAS FINALES

### Tiempos Estimados (Hardware Reference: NVIDIA RTX 3090 / 32GB RAM)

1. **GPA computation:** ~2-3 segundos
2. **Ensemble evaluation (sin TTA):** ~10-15 minutos
3. **Ensemble evaluation (con TTA):** ~30-45 minutos
4. **Generate predictions cache:** ~1-2 horas
5. **Generate warped dataset:** ~2-3 horas
6. **Train classifier (GPU):** ~2-4 horas
7. **Evaluate classifier:** ~2-5 minutos
8. **Quickstart warping (completo):** ~4-8 horas

### Hardware Alternativo (CPU only / 16GB RAM)

- Multiplica tiempos por 5-10x
- Considera reducir batch_size en configs
- Usa --no-tta para evaluaciones m√°s r√°pidas

### Recursos Externos

- **Dataset:** https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database
- **Repo original:** https://github.com/Rhaink/prediccion_warping_clasificacion
- **Documentaci√≥n:** `docs/MIGRATION_NOTES.md`, `CLAUDE.md`

### Contacto para Issues

- Crear issue en GitHub (si el repo es p√∫blico)
- Revisar `GROUND_TRUTH.json` para valores de referencia
- Verificar logs en `outputs/` y `.log` files

---

**FIN DEL PLAN DE PRUEBAS MANUALES**

---
---

# PLAN DE EJECUCI√ìN AUTOMATIZADA

## Fases a Ejecutar

### Fase 1: Preparaci√≥n y Verificaci√≥n de Estructura ‚úÖ
**Tiempo estimado:** 1 minuto

**Acciones:**
1. Cambiar directorio de trabajo a `/home/donrobot/Projects/LungAlignment`
2. Verificar existencia de:
   - `src_v2/` (43 archivos Python esperados)
   - `configs/` (11 JSON esperados)
   - `checkpoints/ensemble_seed{123,321,111,666}/final_model.pt` (4 modelos)
   - `data/coordenadas/coordenadas_maestro.csv`
   - `GROUND_TRUTH.json`
   - `.venv/`
3. Contar archivos y verificar estructura

**Criterios de √©xito:**
- Todos los directorios y archivos cr√≠ticos existen
- Checkpoints en estructura simplificada (`ensemble_seed*/`)
- coordenadas_maestro.csv tiene 958 l√≠neas

---

### Fase 2: Validaci√≥n de Checkpoints PyTorch ‚úÖ
**Tiempo estimado:** 30 segundos

**Acciones:**
1. Activar venv: `source .venv/bin/activate`
2. Cargar los 4 checkpoints con PyTorch
3. Verificar integridad:
   - Claves: `model_state_dict`, `history`
   - N√∫mero de par√°metros: ~11.9M cada uno
   - Sin errores de carga

**Criterios de √©xito:**
- 4/4 checkpoints cargan sin errores
- Cada modelo tiene ~11,893,043 par√°metros
- Estructura de estado v√°lida

---

### Fase 3: Prueba del CLI ‚úÖ
**Tiempo estimado:** 30 segundos

**Acciones:**
1. Ejecutar `python -m src_v2 --help`
2. Verificar comandos disponibles:
   - `compute-canonical`
   - `evaluate-ensemble`
   - `generate-dataset`
   - `train-classifier`
   - `evaluate-classifier`
3. Probar ayuda de comandos individuales

**Criterios de √©xito:**
- CLI responde sin errores
- Todos los comandos esperados est√°n disponibles
- Ayuda se muestra correctamente

---

### Fase 4: GPA (Forma Can√≥nica) ‚úÖ
**Tiempo estimado:** 3-5 segundos

**Acciones:**
1. Ejecutar:
   ```bash
   python -m src_v2 compute-canonical \
     data/coordenadas/coordenadas_maestro.csv \
     -o outputs/shape_analysis_validation \
     --visualize
   ```
2. Verificar outputs:
   - `canonical_shape_gpa.json` (15 landmarks)
   - `canonical_delaunay_triangles.json` (18 tri√°ngulos)
   - `aligned_shapes.npz`
   - Figuras PNG generadas

**Criterios de √©xito:**
- 957 formas procesadas
- 18 tri√°ngulos Delaunay generados
- GPA completa sin errores
- JSON v√°lidos generados

---

### Fase 5: Ensemble Evaluation (CR√çTICO) ‚úÖ
**Tiempo estimado:** 2-3 minutos (GPU) o 10-15 minutos (CPU)

**Acciones:**
1. Verificar que `configs/ensemble_best.json` apunta a estructura correcta:
   ```json
   "checkpoints/ensemble_seed123/final_model.pt"
   ```
2. Ejecutar evaluaci√≥n:
   ```bash
   python scripts/evaluate_ensemble_from_config.py \
     --config configs/ensemble_best.json \
     --out outputs/validation_ensemble_test.log
   ```
3. Extraer m√©tricas del resultado:
   - Error promedio (debe ser ~3.61 px)
   - Error mediana
   - Error std
   - Error por landmark
   - Error por categor√≠a

**Criterios de √©xito:**
- **Error promedio: 3.61 ¬± 0.3 px** (coincide con GROUND_TRUTH.json)
- Sin errores de carga de modelos
- TTA y CLAHE aplicados correctamente
- Resultado en 96 muestras de test

---

### Fase 6: M√≥dulos Python (Verificaci√≥n R√°pida) ‚úÖ
**Tiempo estimado:** 30 segundos

**Acciones:**
1. Test de m√≥dulo GPA:
   ```python
   from src_v2.processing.gpa import gpa_iterative, compute_delaunay_triangulation
   # Test con formas aleatorias
   ```
2. Test de m√≥dulo Warping:
   ```python
   from src_v2.processing.warp import piecewise_affine_warp
   # Test con imagen aleatoria
   ```
3. Verificar imports b√°sicos:
   - `src_v2.models.resnet_landmark`
   - `src_v2.models.classifier`
   - `src_v2.data.transforms`

**Criterios de √©xito:**
- M√≥dulos importan sin errores
- Funciones ejecutan con datos de prueba
- No hay dependencias faltantes

---

### Fase 7: Comparaci√≥n con Ground Truth ‚úÖ
**Tiempo estimado:** 10 segundos

**Acciones:**
1. Cargar `GROUND_TRUTH.json`
2. Extraer valores esperados:
   - Ensemble: 3.61 px
   - Clasificador: 98.05%
   - Margin: 1.05
   - CLAHE tile: 4
3. Comparar con resultados de Fase 5
4. Marcar coincidencias/diferencias

**Criterios de √©xito:**
- Ensemble error coincide con GT: 3.61 px
- Todos los hiperpar√°metros coinciden
- No hay regresiones

---

### Fase 8: Generaci√≥n de Reporte Final ‚úÖ
**Tiempo estimado:** 30 segundos

**Acciones:**
1. Compilar todos los resultados de las fases anteriores
2. Crear reporte Markdown: `TEST_VALIDATION_REPORT_LUNGALIGNMENT.md`
3. Incluir:
   - Resumen ejecutivo con ‚úÖ/‚ùå
   - Resultados detallados por fase
   - Comparaci√≥n con GROUND_TRUTH.json
   - Checklist completo
   - Observaciones y recomendaciones
4. Guardar en el directorio ra√≠z de LungAlignment

**Criterios de √©xito:**
- Reporte generado en formato Markdown
- Todos los tests cr√≠ticos documentados
- Estado final: PASS/FAIL claramente indicado
- Reporte listo para revisi√≥n del usuario

---

## Archivos Cr√≠ticos del Proyecto

**Checkpoints (4):**
- `checkpoints/ensemble_seed123/final_model.pt`
- `checkpoints/ensemble_seed321/final_model.pt`
- `checkpoints/ensemble_seed111/final_model.pt`
- `checkpoints/ensemble_seed666/final_model.pt`

**Configuraciones:**
- `configs/ensemble_best.json` (debe apuntar a ensemble_seed*)
- `configs/warping_best.json`
- `configs/classifier_warped_base.json`

**Datos:**
- `data/coordenadas/coordenadas_maestro.csv` (957 muestras + 1 header)
- `GROUND_TRUTH.json` (valores de referencia v2.1.0)

**Scripts de evaluaci√≥n:**
- `scripts/evaluate_ensemble_from_config.py`
- `scripts/analyze_data.py`

---

## Verificaci√≥n de Ruta de Configuraci√≥n

**ANTES de ejecutar Fase 5, verificar:**

```bash
cat configs/ensemble_best.json
```

**Debe mostrar:**
```json
{
  "models": [
    "checkpoints/ensemble_seed123/final_model.pt",
    "checkpoints/ensemble_seed321/final_model.pt",
    "checkpoints/ensemble_seed111/final_model.pt",
    "checkpoints/ensemble_seed666/final_model.pt"
  ]
}
```

**NO debe mostrar rutas con `session10/`, `session13/`, etc.**

Si las rutas son incorrectas, corregir antes de continuar.

---

## Tiempo Total Estimado

**Hardware: GPU disponible**
- Total: ~5-8 minutos (todas las fases cr√≠ticas)

**Hardware: CPU only**
- Total: ~20-30 minutos

---

## Estado Esperado al Final

```
‚úÖ Fase 1: Estructura verificada
‚úÖ Fase 2: 4/4 checkpoints v√°lidos (~11.9M params cada uno)
‚úÖ Fase 3: CLI funcional (12 comandos disponibles)
‚úÖ Fase 4: GPA exitoso (957 formas ‚Üí 18 tri√°ngulos)
‚úÖ Fase 5: Ensemble = 3.61 px ‚≠ê CR√çTICO
‚úÖ Fase 6: M√≥dulos Python funcionales
‚úÖ Fase 7: Coincidencia con GROUND_TRUTH.json
‚úÖ Fase 8: Reporte generado

STATUS: ‚úÖ ALL CRITICAL TESTS PASSED - READY FOR DELIVERY
```

---

## Notas de Implementaci√≥n

1. **Siempre trabajar en LungAlignment:**
   - Todos los comandos `cd /home/donrobot/Projects/LungAlignment` primero
   - Activar venv: `source .venv/bin/activate`
   - NO usar prediccion_warping_clasificacion

2. **Manejo de errores:**
   - Si Fase 5 falla con error de rutas ‚Üí verificar configs/ensemble_best.json
   - Si imports fallan ‚Üí verificar que venv est√° activado
   - Si dataset no existe ‚Üí marcar como SKIPPED (opcional)

3. **Outputs:**
   - Todos los outputs en `outputs/` dentro de LungAlignment
   - Reporte final en ra√≠z: `TEST_VALIDATION_REPORT_LUNGALIGNMENT.md`
   - Logs de ensemble en `outputs/validation_ensemble_test.log`

---

**FIN DEL PLAN DE EJECUCI√ìN**
